{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/scott/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data folder if does not already exist\n",
    "import os\n",
    "if not os.path.exists('data/'):\n",
    "    os.makedirs('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine IDs of articles to scrape\n",
    "ELife since 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (4,5,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load database of available articles\n",
    "df = pd.read_csv('/gh/data/opencode/PMC-ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep = df[df['Journal Title']=='eLife']\n",
    "df_keep = df_keep[df_keep['Year']>=2014]\n",
    "df_keep.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal Title</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>eISSN</th>\n",
       "      <th>Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Page</th>\n",
       "      <th>DOI</th>\n",
       "      <th>PMCID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Manuscript Id</th>\n",
       "      <th>Release Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eLife</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2050-084X</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e01539</td>\n",
       "      <td>10.7554/eLife.01539</td>\n",
       "      <td>PMC3881093</td>\n",
       "      <td>24399458.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eLife</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2050-084X</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e01386</td>\n",
       "      <td>10.7554/eLife.01386</td>\n",
       "      <td>PMC3882429</td>\n",
       "      <td>24399457.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eLife</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2050-084X</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e01928</td>\n",
       "      <td>10.7554/eLife.01928</td>\n",
       "      <td>PMC3882917</td>\n",
       "      <td>24399459.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eLife</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2050-084X</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e01385</td>\n",
       "      <td>10.7554/eLife.01385</td>\n",
       "      <td>PMC3884117</td>\n",
       "      <td>24424411.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eLife</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2050-084X</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e01457</td>\n",
       "      <td>10.7554/eLife.01457</td>\n",
       "      <td>PMC3885792</td>\n",
       "      <td>24424413.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Journal Title ISSN      eISSN  Year Volume Issue    Page  \\\n",
       "0         eLife  NaN  2050-084X  2014      3   NaN  e01539   \n",
       "1         eLife  NaN  2050-084X  2014      3   NaN  e01386   \n",
       "2         eLife  NaN  2050-084X  2014      3   NaN  e01928   \n",
       "3         eLife  NaN  2050-084X  2014      3   NaN  e01385   \n",
       "4         eLife  NaN  2050-084X  2014      3   NaN  e01457   \n",
       "\n",
       "                   DOI       PMCID        PMID Manuscript Id Release Date  \n",
       "0  10.7554/eLife.01539  PMC3881093  24399458.0           NaN         live  \n",
       "1  10.7554/eLife.01386  PMC3882429  24399457.0           NaN         live  \n",
       "2  10.7554/eLife.01928  PMC3882917  24399459.0           NaN         live  \n",
       "3  10.7554/eLife.01385  PMC3884117  24424411.0           NaN         live  \n",
       "4  10.7554/eLife.01457  PMC3885792  24424413.0           NaN         live  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = open('apikey.txt', 'r').read()\n",
    "db = 'pmc'\n",
    "base = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keywords\n",
    "with open('keywords.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    terms = list(reader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of characters to extract around keywords\n",
    "span_buffer = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving parameters\n",
    "N_previous = 600\n",
    "N_chunk = 10000\n",
    "N_save = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/data shared_4850.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-72272d4ae04f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mdf_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_articles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdf_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/{:s}_{:d}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/{:s}_{:d}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_save\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data shared_4850.csv'"
     ]
    }
   ],
   "source": [
    "# Load previous computation\n",
    "if N_previous > 0:\n",
    "    dfs_articles = {}\n",
    "    for k in terms:\n",
    "        csv_name = 'data/{:s}_{:d}.csv'.format(k, N_previous)\n",
    "        dfs_articles[k] = [pd.read_csv(csv_name, index_col=0)]\n",
    "else:\n",
    "    dfs_articles = defaultdict(list)\n",
    "\n",
    "for i, row in df_keep.loc[N_previous+1:].iterrows():\n",
    "    # Get full text of 1 paper\n",
    "    pmcid = row['PMCID']\n",
    "    s = '{:s}db={:s}&id={:s}'.format(base, db, pmcid, apikey)\n",
    "    out = requests.get(s)\n",
    "    bs = BeautifulSoup(out.content, 'lxml')\n",
    "\n",
    "    # DFs of terms\n",
    "    for term in terms:\n",
    "        dict_term = defaultdict(list)\n",
    "        for s in re.finditer(term, out.text, re.IGNORECASE):\n",
    "            save_span = s.span()\n",
    "            sent = out.text[(save_span[0] - span_buffer):(save_span[1] + span_buffer)]\n",
    "\n",
    "            dict_term['PMCID'].append(pmcid)\n",
    "            dict_term['sentence'].append(sent)\n",
    "        dfs_articles[term].append(pd.DataFrame(dict_term))\n",
    "\n",
    "    # Save output every N\n",
    "    if (i % N_save == 0) & (i > 0):\n",
    "        print(i)\n",
    "        for k in dfs_articles.keys():\n",
    "            df_save = pd.concat(dfs_articles[k])\n",
    "            df_save.to_csv('data/{:s}_{:d}.csv'.format(k, i))\n",
    "\n",
    "            # Delete last file Unless \n",
    "            if (i-N_save) % N_chunk > 0:\n",
    "                os.remove('data/{:s}_{:d}.csv'.format(k, i - N_save))\n",
    "\n",
    "        if i % N_chunk == 0:\n",
    "            if i > 0:\n",
    "                dfs_articles = defaultdict(list)\n",
    "            \n",
    "# Save output when finish\n",
    "for k in dfs_articles.keys():\n",
    "    df_save = pd.concat(dfs_articles[k])\n",
    "    df_save.to_csv('data/{:s}_{:d}.csv'.format(k, i))\n",
    "    os.remove('data/{:s}_{:d}.csv'.format(k, int(np.round(i-(N_save/2-1), -2))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
